{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel='stylesheet' href='../assets/css/main.css'/>\n",
    "\n",
    "[<< back to main index](../README.md)\n",
    "\n",
    "# Naive Bayes Spam Filtering\n",
    "\n",
    "### Overview\n",
    "\n",
    "We all hate spam, so developing a classifier to classify email as spam or not spam is useful.  \n",
    "\n",
    "### Builds on\n",
    "None\n",
    "\n",
    "### Run time\n",
    "approx. 20-30 minutes\n",
    "\n",
    "### Notes\n",
    "\n",
    "PySpark has a class called NaiveBayes that can be used to do Naive Bayes classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark UI running on http://18.208.221.237:4040\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print('Spark UI running on http://18.208.221.237:' + sc.uiWebUrl.split(':')[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Let's load the dataframe\n",
    "\n",
    "We will load the dataframe into spark.  Since the outcome label is \"ham\" or \"spam\", we'll just call it label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "attributes": {
     "classes": [
      "R"
     ],
     "id": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 5,574 records in 128.62 ms\n",
      "root\n",
      " |-- isspam: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      "\n",
      "+------+--------------------+\n",
      "|isspam|                text|\n",
      "+------+--------------------+\n",
      "|   ham|Go until jurong p...|\n",
      "|   ham|Ok lar... Joking ...|\n",
      "|  spam|Free entry in 2 a...|\n",
      "|   ham|U dun say so earl...|\n",
      "|   ham|Nah I don't think...|\n",
      "|  spam|FreeMsg Hey there...|\n",
      "|   ham|Even my brother i...|\n",
      "|   ham|As per your reque...|\n",
      "|  spam|WINNER!! As a val...|\n",
      "|  spam|Had your mobile 1...|\n",
      "|   ham|I'm gonna be home...|\n",
      "|  spam|SIX chances to wi...|\n",
      "|  spam|URGENT! You have ...|\n",
      "|   ham|I've been searchi...|\n",
      "|   ham|I HAVE A DATE ON ...|\n",
      "|  spam|XXXMobileMovieClu...|\n",
      "|   ham|Oh k...i'm watchi...|\n",
      "|   ham|Eh u remember how...|\n",
      "|   ham|Fine if thats th...|\n",
      "|  spam|England v Macedon...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1 = time.perf_counter()\n",
    "\n",
    "dataset = spark.read.format(\"csv\").\\\n",
    "          option('header','true').\\\n",
    "          option('delimiter', '\\t').\\\n",
    "          option('inferSchema', 'true').\\\n",
    "          load(\"/data/spam/SMSSpamCollection.txt\")\n",
    "\n",
    "t2 = time.perf_counter() \n",
    "\n",
    "print(\"read {:,} records in {:,.2f} ms\".format(dataset.count(), (t2-t1)*1000))\n",
    "\n",
    "dataset.printSchema()\n",
    "dataset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|isspam|count|\n",
      "+------+-----+\n",
      "|   ham| 4827|\n",
      "|  spam|  747|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Count spam/ham\n",
    "dataset.groupby(\"isspam\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Vectorize using tf/idf\n",
    "\n",
    "Let's use tf/idf for vecorization at first.  TF/IDF will take and count the instances of each term, and then divide by the total frequecy of that term in the entire dataset.  \n",
    "\n",
    "This leads to very highly dimensional data, because every word in the document will lead to a dimension in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|isspam|                text|               words|\n",
      "+------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|[go, until, juron...|\n",
      "|   ham|Ok lar... Joking ...|[ok, lar..., joki...|\n",
      "|  spam|Free entry in 2 a...|[free, entry, in,...|\n",
      "|   ham|U dun say so earl...|[u, dun, say, so,...|\n",
      "|   ham|Nah I don't think...|[nah, i, don't, t...|\n",
      "|  spam|FreeMsg Hey there...|[freemsg, hey, th...|\n",
      "|   ham|Even my brother i...|[even, my, brothe...|\n",
      "|   ham|As per your reque...|[as, per, your, r...|\n",
      "|  spam|WINNER!! As a val...|[winner!!, as, a,...|\n",
      "|  spam|Had your mobile 1...|[had, your, mobil...|\n",
      "|   ham|I'm gonna be home...|[i'm, gonna, be, ...|\n",
      "|  spam|SIX chances to wi...|[six, chances, to...|\n",
      "|  spam|URGENT! You have ...|[urgent!, you, ha...|\n",
      "|   ham|I've been searchi...|[i've, been, sear...|\n",
      "|   ham|I HAVE A DATE ON ...|[i, have, a, date...|\n",
      "|  spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|\n",
      "|   ham|Oh k...i'm watchi...|[oh, k...i'm, wat...|\n",
      "|   ham|Eh u remember how...|[eh, u, remember,...|\n",
      "|   ham|Fine if thats th...|[fine, if, thats...|\n",
      "|  spam|England v Macedon...|[england, v, mace...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "## TODO : split the text into words\n",
    "## Hint : outputCol = 'words'\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(dataset)\n",
    "wordsData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|isspam|                text|               words|         rawFeatures|            features|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|[go, until, juron...|(1000,[7,77,150,1...|(1000,[7,77,150,1...|\n",
      "|   ham|Ok lar... Joking ...|[ok, lar..., joki...|(1000,[20,316,484...|(1000,[20,316,484...|\n",
      "|  spam|Free entry in 2 a...|[free, entry, in,...|(1000,[30,35,73,1...|(1000,[30,35,73,1...|\n",
      "|   ham|U dun say so earl...|[u, dun, say, so,...|(1000,[57,368,372...|(1000,[57,368,372...|\n",
      "|   ham|Nah I don't think...|[nah, i, don't, t...|(1000,[135,163,32...|(1000,[135,163,32...|\n",
      "|  spam|FreeMsg Hey there...|[freemsg, hey, th...|(1000,[25,36,68,9...|(1000,[25,36,68,9...|\n",
      "|   ham|Even my brother i...|[even, my, brothe...|(1000,[18,47,48,5...|(1000,[18,47,48,5...|\n",
      "|   ham|As per your reque...|[as, per, your, r...|(1000,[36,71,92,2...|(1000,[36,71,92,2...|\n",
      "|  spam|WINNER!! As a val...|[winner!!, as, a,...|(1000,[39,43,61,7...|(1000,[39,43,61,7...|\n",
      "|  spam|Had your mobile 1...|[had, your, mobil...|(1000,[36,73,82,1...|(1000,[36,73,82,1...|\n",
      "|   ham|I'm gonna be home...|[i'm, gonna, be, ...|(1000,[26,41,106,...|(1000,[26,41,106,...|\n",
      "|  spam|SIX chances to wi...|[six, chances, to...|(1000,[15,35,36,4...|(1000,[15,35,36,4...|\n",
      "|  spam|URGENT! You have ...|[urgent!, you, ha...|(1000,[68,73,122,...|(1000,[68,73,122,...|\n",
      "|   ham|I've been searchi...|[i've, been, sear...|(1000,[19,36,39,1...|(1000,[19,36,39,1...|\n",
      "|   ham|I HAVE A DATE ON ...|[i, have, a, date...|(1000,[44,82,170,...|(1000,[44,82,170,...|\n",
      "|  spam|XXXMobileMovieClu...|[xxxmobilemoviecl...|(1000,[41,43,49,6...|(1000,[41,43,49,6...|\n",
      "|   ham|Oh k...i'm watchi...|[oh, k...i'm, wat...|(1000,[275,426,44...|(1000,[275,426,44...|\n",
      "|   ham|Eh u remember how...|[eh, u, remember,...|(1000,[80,147,236...|(1000,[80,147,236...|\n",
      "|   ham|Fine if thats th...|[fine, if, thats...|(1000,[80,159,170...|(1000,[80,159,170...|\n",
      "|  spam|England v Macedon...|[england, v, mace...|(1000,[9,19,45,71...|(1000,[9,19,45,71...|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## compute the hash of words\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+\n",
      "|isspam|                text|            features|\n",
      "+------+--------------------+--------------------+\n",
      "|   ham|Go until jurong p...|(1000,[7,77,150,1...|\n",
      "|   ham|Ok lar... Joking ...|(1000,[20,316,484...|\n",
      "|  spam|Free entry in 2 a...|(1000,[30,35,73,1...|\n",
      "|   ham|U dun say so earl...|(1000,[57,368,372...|\n",
      "|   ham|Nah I don't think...|(1000,[135,163,32...|\n",
      "|  spam|FreeMsg Hey there...|(1000,[25,36,68,9...|\n",
      "|   ham|Even my brother i...|(1000,[18,47,48,5...|\n",
      "|   ham|As per your reque...|(1000,[36,71,92,2...|\n",
      "|  spam|WINNER!! As a val...|(1000,[39,43,61,7...|\n",
      "|  spam|Had your mobile 1...|(1000,[36,73,82,1...|\n",
      "|   ham|I'm gonna be home...|(1000,[26,41,106,...|\n",
      "|  spam|SIX chances to wi...|(1000,[15,35,36,4...|\n",
      "|  spam|URGENT! You have ...|(1000,[68,73,122,...|\n",
      "|   ham|I've been searchi...|(1000,[19,36,39,1...|\n",
      "|   ham|I HAVE A DATE ON ...|(1000,[44,82,170,...|\n",
      "|  spam|XXXMobileMovieClu...|(1000,[41,43,49,6...|\n",
      "|   ham|Oh k...i'm watchi...|(1000,[275,426,44...|\n",
      "|   ham|Eh u remember how...|(1000,[80,147,236...|\n",
      "|   ham|Fine if thats th...|(1000,[80,159,170...|\n",
      "|  spam|England v Macedon...|(1000,[9,19,45,71...|\n",
      "+------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rescaledData.select(\"isspam\", \"text\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Create a numeric label out of the string column \"isspam.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+--------------------+\n",
      "|                text|isspam|label|            features|\n",
      "+--------------------+------+-----+--------------------+\n",
      "|Go until jurong p...|   ham|  0.0|(1000,[7,77,150,1...|\n",
      "|Ok lar... Joking ...|   ham|  0.0|(1000,[20,316,484...|\n",
      "|Free entry in 2 a...|  spam|  1.0|(1000,[30,35,73,1...|\n",
      "|U dun say so earl...|   ham|  0.0|(1000,[57,368,372...|\n",
      "|Nah I don't think...|   ham|  0.0|(1000,[135,163,32...|\n",
      "|FreeMsg Hey there...|  spam|  1.0|(1000,[25,36,68,9...|\n",
      "|Even my brother i...|   ham|  0.0|(1000,[18,47,48,5...|\n",
      "|As per your reque...|   ham|  0.0|(1000,[36,71,92,2...|\n",
      "|WINNER!! As a val...|  spam|  1.0|(1000,[39,43,61,7...|\n",
      "|Had your mobile 1...|  spam|  1.0|(1000,[36,73,82,1...|\n",
      "|I'm gonna be home...|   ham|  0.0|(1000,[26,41,106,...|\n",
      "|SIX chances to wi...|  spam|  1.0|(1000,[15,35,36,4...|\n",
      "|URGENT! You have ...|  spam|  1.0|(1000,[68,73,122,...|\n",
      "|I've been searchi...|   ham|  0.0|(1000,[19,36,39,1...|\n",
      "|I HAVE A DATE ON ...|   ham|  0.0|(1000,[44,82,170,...|\n",
      "|XXXMobileMovieClu...|  spam|  1.0|(1000,[41,43,49,6...|\n",
      "|Oh k...i'm watchi...|   ham|  0.0|(1000,[275,426,44...|\n",
      "|Eh u remember how...|   ham|  0.0|(1000,[80,147,236...|\n",
      "|Fine if thats th...|   ham|  0.0|(1000,[80,159,170...|\n",
      "|England v Macedon...|  spam|  1.0|(1000,[9,19,45,71...|\n",
      "+--------------------+------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "## TODO : Index 'isspam' column into 'label' column\n",
    "## Hint : inputCol = 'isspam',   outputCol = 'label'\n",
    "indexer = StringIndexer(inputCol=\"isspam\", outputCol=\"label\")\n",
    "indexed = indexer.fit(rescaledData).transform(rescaledData)\n",
    "\n",
    "indexed.select(['text', 'isspam', 'label', 'features']).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Split into training and test\n",
    "\n",
    "We will split our dataset into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set count :  4489\n",
      "testing set count :  1085\n"
     ]
    }
   ],
   "source": [
    "# TODO : Split the data into train and test into 80/20\n",
    "(train, test) = indexed.randomSplit([80.0, 20.0])\n",
    "\n",
    "print(\"training set count : \", train.count())\n",
    "print(\"testing set count : \", test.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fit Naive Bayes model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained on 4,489 records  in 983.07 ms\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "\n",
    "## TODO : create the trainer and set its parameters\n",
    "## Hint : NaiveBayes  (see the class name above)\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")\n",
    "\n",
    "# train the model\n",
    "t1 = time.perf_counter()\n",
    "## TODO : fit on training data (hint: train)\n",
    "model = nb.fit(train)\n",
    "t2 = time.perf_counter()\n",
    "\n",
    "print(\"trained on {:,} records  in {:,.2f} ms\".\\\n",
    "      format(train.count(), (t2-t1)*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run test data\n",
    "\n",
    "Let's call .transform on our model to do make predictions on our test data. The output should be contained in the \"prediction\" column, while the correct label will be there in the \"label\" column. \n",
    "\n",
    "We will be able to evaluate our results by comparing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|isspam|                text|               words|         rawFeatures|            features|label|       rawPrediction|         probability|prediction|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "|   ham| said kiss, kiss,...|[, said, kiss,, k...|(1000,[44,51,133,...|(1000,[44,51,133,...|  0.0|[-638.12813753362...|[1.0,2.2669448674...|       0.0|\n",
      "|   ham| says that he's q...|[, says, that, he...|(1000,[38,122,138...|(1000,[38,122,138...|  0.0|[-887.09354460589...|[1.0,1.2982581398...|       0.0|\n",
      "|   ham|\"SYMPTOMS\" when U...|[\"symptoms\", when...|(1000,[15,76,138,...|(1000,[15,76,138,...|  0.0|[-604.72010787181...|[1.0,3.6560762633...|       0.0|\n",
      "|   ham|&lt;#&gt; , that'...|[&lt;#&gt;, ,, th...|(1000,[88,597,760...|(1000,[88,597,760...|  0.0|[-206.24889064359...|[1.0,4.5815220384...|       0.0|\n",
      "|   ham|'An Amazing Quote...|['an, amazing, qu...|(1000,[10,16,40,1...|(1000,[10,16,40,1...|  0.0|[-609.51643258293...|[0.99999999981515...|       0.0|\n",
      "|   ham|* Am on a train b...|[*, am, on, a, tr...|(1000,[30,34,52,8...|(1000,[30,34,52,8...|  0.0|[-252.45130377047...|[0.00663535496343...|       1.0|\n",
      "|   ham|* Thought I didn'...|[*, thought, i, d...|(1000,[4,34,329,5...|(1000,[4,34,329,5...|  0.0|[-131.14231086344...|[0.99999999999999...|       0.0|\n",
      "|   ham|* Was really good...|[*, was, really, ...|(1000,[34,168,234...|(1000,[34,168,234...|  0.0|[-295.13576766646...|[0.99999999998550...|       0.0|\n",
      "|   ham|, im .. On the sn...|[,, im, .., on, t...|(1000,[7,32,44,61...|(1000,[7,32,44,61...|  0.0|[-621.09705900132...|[1.0,4.5437805822...|       0.0|\n",
      "|   ham|1 in cbe. 2 in ch...|[1, in, cbe., 2, ...|(1000,[445,458,74...|(1000,[445,458,74...|  0.0|[-141.23192634547...|[0.17432193452214...|       1.0|\n",
      "|   ham|1) Go to write ms...|[1), go, to, writ...|(1000,[19,56,68,7...|(1000,[19,56,68,7...|  0.0|[-618.18061915847...|[1.0,8.3620555657...|       0.0|\n",
      "|   ham|1. Tension face 2...|[1., tension, fac...|(1000,[8,34,128,1...|(1000,[8,34,128,1...|  0.0|[-745.16327415004...|[1.0,5.4256238716...|       0.0|\n",
      "|   ham|2marrow only. Wed...|[2marrow, only., ...|(1000,[61,300,372...|(1000,[61,300,372...|  0.0|[-242.56886174023...|[0.99999999999998...|       0.0|\n",
      "|   ham|2mro i am not com...|[2mro, i, am, not...|(1000,[18,173,185...|(1000,[18,173,185...|  0.0|[-195.96956819107...|[0.99999999971448...|       0.0|\n",
      "|   ham|                 645|               [645]|   (1000,[92],[1.0])|(1000,[92],[4.694...|  0.0|[-34.003324223436...|[0.88166243372945...|       0.0|\n",
      "|   ham|;-) ok. I feel li...|[;-), ok., i, fee...|(1000,[115,329,33...|(1000,[115,329,33...|  0.0|[-195.36530640765...|[0.99999998708112...|       0.0|\n",
      "|   ham|A Boy loved a gal...|[a, boy, loved, a...|(1000,[24,29,62,6...|(1000,[24,29,62,6...|  0.0|[-2652.4549474160...|[1.0,1.8326163685...|       0.0|\n",
      "|   ham|A Boy loved a gal...|[a, boy, loved, a...|(1000,[24,29,62,6...|(1000,[24,29,62,6...|  0.0|[-2652.4549474160...|[1.0,1.8326163685...|       0.0|\n",
      "|   ham|A bit of Ur smile...|[a, bit, of, ur, ...|(1000,[19,36,120,...|(1000,[19,36,120,...|  0.0|[-753.97625989397...|[1.0,1.6155041415...|       0.0|\n",
      "|   ham|A boy was late 2 ...|[a, boy, was, lat...|(1000,[79,170,174...|(1000,[79,170,174...|  0.0|[-275.96328518120...|[0.99999934056577...|       0.0|\n",
      "+------+--------------------+--------------------+--------------------+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select example rows to display.\n",
    "## TODO : transform on test data (hint : test)\n",
    "predictions = model.transform(test)\n",
    "predictions.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Evaluate the model\n",
    "\n",
    "Let's look at how our model performs.  We will do an accuracy measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.9345622119815669\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Let us do a confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+\n",
      "|label|  0|  1|\n",
      "+-----+---+---+\n",
      "|  0.0|883| 55|\n",
      "|  1.0| 16|131|\n",
      "+-----+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.groupBy('label').pivot('prediction', [0,1]).count().na.fill(0).orderBy('label').show()\n",
    "\n",
    "## Can you explain the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Improve prediction results\n",
    "\n",
    "We used too few features above, and got bad accuracy. Increase the number of features for HashingTF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Step 9:  Run your own test\n",
    "\n",
    "Now it's your turn!   Make a new dataframe with some sample test data of your own creation.  Make some \"spammy\" SMSes and some ordinary ones.  See how our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                text|               words|\n",
      "+--------------------+--------------------+\n",
      "|hey, can we meet ...|[hey,, can, we, m...|\n",
      "|WINNER!  Click he...|[winner!, , click...|\n",
      "|   CHEAP DEGREEES !!|[cheap, degreees,...|\n",
      "|      your text here|  [your, text, here]|\n",
      "|                test|              [test]|\n",
      "+--------------------+--------------------+\n",
      "\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|               words|         rawFeatures|            features|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "|hey, can we meet ...|[hey,, can, we, m...|(1000,[238,486,74...|(1000,[238,486,74...|\n",
      "|WINNER!  Click he...|[winner!, , click...|(1000,[135,189,26...|(1000,[135,189,26...|\n",
      "|   CHEAP DEGREEES !!|[cheap, degreees,...|(1000,[119,339,66...|(1000,[119,339,66...|\n",
      "|      your text here|  [your, text, here]|(1000,[135,169,26...|(1000,[135,169,26...|\n",
      "|                test|              [test]|  (1000,[586],[1.0])|(1000,[586],[4.60...|\n",
      "+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: make a dataframe with some of your own data.\n",
    "mydata = pd.DataFrame({'text' : ['hey, can we meet 1 hr later?', \n",
    "                                'WINNER!  Click here to claim your prize !!!!',\n",
    "                                'CHEAP DEGREEES !!', \n",
    "                                'your text here',\n",
    "                                'test']\n",
    "                         })\n",
    "\n",
    "mydata2 = spark.createDataFrame(mydata)\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "fv = tokenizer.transform(mydata2)\n",
    "fv.show()\n",
    "\n",
    "## NOTE : make sure this 'numFeatures' matches the 'numFeatures' in step-2\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
    "fv = hashingTF.transform(fv)\n",
    "\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "fv = idfModel.transform(fv)\n",
    "fv.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+\n",
      "|                text|prediction|\n",
      "+--------------------+----------+\n",
      "|hey, can we meet ...|       0.0|\n",
      "|WINNER!  Click he...|       0.0|\n",
      "|   CHEAP DEGREEES !!|       0.0|\n",
      "|      your text here|       1.0|\n",
      "|                test|       0.0|\n",
      "+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(fv)\n",
    "predictions.select(['text', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN : How will you defeat this algorithm? :-) \n",
    "\n",
    "If you are spammer, how can you defeat this algorithm?\n",
    "\n",
    "<img src=\"../assets/images/come-tothe-dark-side-iin-we-have-cookies.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# BONUS: Word2Vec Instead of TF/IDF\n",
    "\n",
    "We used the TF/IDF encoding. We might get better resu\n",
    "\n",
    "lts if we use Word2Vec instead. Run with word2vec and see if you get a better accuracy rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
